{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "{'Client ID': 'Syv7stn-Rd-mtrudAbRvuaqMUb_AgdSirVvOb9XofEnxQ4_oYlVzptzilTlFhbcq',\n",
    "    'Client Secret':'A0fegVhhiemDPVDdDdtYkW-8j9GF-d6pFv4_-_sbuX7Hm3yOzqlPL-HRof0bzHYu9x-CaYc0ak9AMQ3ZIYt_Ig',\n",
    "'Client Access Token': 'HIs4ia8HMYMSYsZVHrYSFdAhcum7gHC0ZWMPa5pXJOoQUhd86oe6maD-BkIcKrnz'\n",
    "\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-14T06:02:15.635450Z",
     "start_time": "2018-08-14T06:02:15.628661Z"
    }
   },
   "outputs": [],
   "source": [
    "export GENIUS_CLIENT_ACCESS_TOKEN=\"HIs4ia8HMYMSYsZVHrYSFdAhcum7gHC0ZWMPa5pXJOoQUhd86oe6maD-BkIcKrnz\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing necessary modules and files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-15T05:55:40.454870Z",
     "start_time": "2018-08-15T05:55:38.831324Z"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-15T05:56:58.677194Z",
     "start_time": "2018-08-15T05:56:58.674369Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# loading data\n",
    "\n",
    "df = pd.read_csv('lyrics.csv')\n",
    "billboard = pd.read_csv('billboards.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-15T05:56:59.049178Z",
     "start_time": "2018-08-15T05:56:58.877361Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-69e3e216127c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'lyrics.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# after looking at the first element of the lyrics column, I need to be remove all the spacing and annotations in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# the csv database as well as the scraped lyrics, because its not consistent with the other elements in the lyrics album\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'song'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msong\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'artist'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "#df = pd.read_csv('lyrics.csv')\n",
    "# after looking at the first element of the lyrics column, I need to be remove all the spacing and annotations in \n",
    "# the csv database as well as the scraped lyrics, because its not consistent with the other elements in the lyrics album\n",
    "df['song'] = df.song.str.replace('-', \" \")\n",
    "df['artist'] = df.artist.str.replace('-', \" \")\n",
    "df['lyrics'] = df.lyrics.str.replace('\\n', ' ')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-15T05:56:00.003129Z",
     "start_time": "2018-08-15T05:55:59.969036Z"
    }
   },
   "outputs": [],
   "source": [
    "# cool after I finish cleaning this dataset, i need to figure out how to find the lyrics for the songs from my\n",
    "# previous project. let me load the dataset into this project repo first\n",
    "\n",
    "billboard = pd.read_csv('billboards.csv')\n",
    "billboard.Song = billboard.Song.str.replace('>', 'than')\n",
    "billboard.Artist = billboard.Artist.str.replace(' x ', ', ')\n",
    "billboard.drop('num_weeks', inplace = True, axis = 1)\n",
    "# billboard.head(20)\n",
    "\n",
    "billboard_dict = billboard.to_dict('records')\n",
    "billboard_dict[:5]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing out the thought process to get to the final product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "\n",
    "1. punctuation like $ will be replaced by '-' in the url\n",
    "\n",
    "1. multiple artists will be in the url, so maybe i need to get all of the artists from the spotify api? put in a try/except so that i can keep track of all the songs that didn't work and do that later for a smaller subset of songs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-15T05:01:48.035230Z",
     "start_time": "2018-08-15T05:01:47.341556Z"
    }
   },
   "outputs": [],
   "source": [
    "from nltk import sent_tokenize, word_tokenize\n",
    "\n",
    "\n",
    "# grabbing the data from the url\n",
    "artist = 'Tessa Violet'\n",
    "artist_url = artist.lower().replace(' ', '-')\n",
    "\n",
    "source_code = requests.get(f'https://genius.com/{artist_url}-crush-lyrics')\n",
    "soup = BeautifulSoup(source_code.text, 'html5lib')\n",
    "lyrics = soup.find('div', class_='lyrics').text.strip()\n",
    "\n",
    "#cleaning\n",
    "\n",
    "lyrics = lyrics.replace('\\n', '. ')\n",
    "sentences = sent_tokenize(lyrics)\n",
    "cleaned = [sentence for sentence in sentences if ('bridge' not in sentence.lower()) and ('verse' not in sentence.lower()) and ('chorus' not in sentence.lower()) and len(sentence) >1]\n",
    "\n",
    "data = [artist, song, cleaned]\n",
    "key =['artist', 'song', 'lyrics']\n",
    "song_dict = dict(zip(key, data))\n",
    "print(song_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-15T05:15:11.765307Z",
     "start_time": "2018-08-15T05:15:10.691574Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "artist = 'Kanye West'\n",
    "artist_url = artist.replace(' ', '-')\n",
    "\n",
    "song = 'All of the Lights'\n",
    "song_url = song.replace(' ', '-')\n",
    "\n",
    "\n",
    "source_code = requests.get(f'https://genius.com/{artist_url}-{song_url}-lyrics')\n",
    "soup = BeautifulSoup(source_code.text, 'html5lib')\n",
    "lyrics = soup.find('div', class_='lyrics').text.strip()\n",
    "\n",
    "#cleaning\n",
    "\n",
    "lyrics = lyrics.replace('\\n', '. ')\n",
    "sentences = sent_tokenize(lyrics)\n",
    "cleaned = [sentence for sentence in sentences if \n",
    "           ('produced' not in sentence.lower()) and\n",
    "           ('intro' not in sentence.lower()) and\n",
    "           ('outro' not in sentence.lower()) and\n",
    "           ('bridge' not in sentence.lower()) and \n",
    "           ('verse' not in sentence.lower()) and \n",
    "           ('chorus' not in sentence.lower()) and len(sentence) >1]\n",
    "cleaned\n",
    "\n",
    "#it would be nice to all of this in a dictionary that i can just put into an array and then turn into a pd dataframe\n",
    "\n",
    "data = [artist, song, cleaned]\n",
    "key =['artist', 'song', 'lyrics']\n",
    "song_dict = dict(zip(key, data))\n",
    "# print(song_dict) #yay it worked\n",
    "# please note it takes like a second for one song..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-15T05:05:27.024217Z",
     "start_time": "2018-08-15T05:05:26.293805Z"
    }
   },
   "outputs": [],
   "source": [
    "# https://genius.com/2-chainz-bigger-than-you-lyrics\n",
    "    \n",
    "source_code = requests.get('https://genius.com/2-chainz-bigger-than-you-lyrics')\n",
    "soup = BeautifulSoup(source_code.text, 'html5lib')\n",
    "lyrics = soup.find('div', class_='lyrics').text.strip()\n",
    "print((lyrics)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "billboard_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-15T05:55:49.370913Z",
     "start_time": "2018-08-15T05:55:49.333524Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# i need to building a function that takes the billboard songs and just scrapes for songs!\n",
    "\n",
    "def scrape_genius(artist, song):\n",
    "    \n",
    "    #artist = 'Kanye West'\n",
    "    artist = artist.replace(\"'\", '')\n",
    "    song = song.replace(\"'\", '')\n",
    "    artist_url = artist.replace(' ', '-')\n",
    "    #artist_url = artist.replace(',-', '-')\n",
    "    #artist_url = artist.replace(',', '')\n",
    "\n",
    "    #song = 'All of the Lights'\n",
    "    song_url = song.replace(' ', '-')\n",
    "\n",
    "    url = f'https://genius.com/{artist_url}-{song_url}-lyrics'\n",
    "    # print(url)\n",
    "    source_code = requests.get(url)\n",
    "    soup = BeautifulSoup(source_code.text, 'html5lib')\n",
    "    lyrics = soup.find('div', class_='lyrics').text.strip()\n",
    "\n",
    "    #cleaning\n",
    "\n",
    "    lyrics = lyrics.replace('\\n', '. ')\n",
    "    sentences = sent_tokenize(lyrics)\n",
    "    cleaned = [sentence for sentence in sentences if \n",
    "               ('produced' not in sentence.lower()) and\n",
    "               ('intro' not in sentence.lower()) and\n",
    "               ('outro' not in sentence.lower()) and\n",
    "               ('bridge' not in sentence.lower()) and \n",
    "               ('verse' not in sentence.lower()) and \n",
    "               ('chorus' not in sentence.lower()) and len(sentence) >1]\n",
    "    cleaned\n",
    "\n",
    "    #it would be nice to all of this in a dictionary that i can just put into an array and then turn into a pd dataframe\n",
    "\n",
    "    data = [artist, song, cleaned]\n",
    "    key =['artist', 'song', 'lyrics']\n",
    "    song_dict = dict(zip(key, data))\n",
    "    return song_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-15T05:55:51.348779Z",
     "start_time": "2018-08-15T05:55:51.254526Z"
    }
   },
   "outputs": [],
   "source": [
    "len(billboard_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finally Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-08-15T05:56:05.751Z"
    }
   },
   "outputs": [],
   "source": [
    "smaller = billboard_dict[:20]\n",
    "\n",
    "lyrics = []\n",
    "missing = []\n",
    "for record in billboard_dict:\n",
    "    song = record['Song']\n",
    "    artist = record['Artist']\n",
    "    artist = artist.replace(', ', ' ')\n",
    "    artist = artist.replace('.', '')\n",
    "    #print(artist, song)\n",
    "    # artist = record['Artist']\n",
    "    try:\n",
    "        lyrics.append(scrape_genius(artist, song))\n",
    "    except:\n",
    "        missing.append(record)\n",
    "        pass\n",
    "    #print(lyrics)\n",
    "    #print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-08-15T05:56:16.456Z"
    }
   },
   "outputs": [],
   "source": [
    "len(missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-08-15T05:51:52.152Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(lyrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-15T05:46:02.270730Z",
     "start_time": "2018-08-15T05:46:02.262690Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "billboard_lyrics = pd.DataFrame(lyrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
